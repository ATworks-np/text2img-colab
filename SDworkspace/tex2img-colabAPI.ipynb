{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"BD-8T6dHJBcY"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd '/content/drive/My Drive/SDworkspace'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RTIfu58NPi9S"},"outputs":[],"source":["!pip install -qq diffusers[\"training\"]==0.3.0 transformers ftfy\n","!pip install -qq \"ipywidgets>=7,<8\"\n","\n","from huggingface_hub import notebook_login\n","notebook_login()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oXBfxsXxJXFh"},"outputs":[],"source":["import argparse\n","import itertools\n","import math\n","import os\n","import random\n","\n","import numpy as np\n","import torch\n","import torch.nn.functional as F\n","import torch.utils.checkpoint\n","from torch.utils.data import Dataset\n","\n","import PIL\n","from accelerate import Accelerator\n","from accelerate.logging import get_logger\n","from accelerate.utils import set_seed\n","from diffusers import AutoencoderKL, DDPMScheduler, PNDMScheduler, StableDiffusionPipeline, UNet2DConditionModel\n","from diffusers.hub_utils import init_git_repo, push_to_hub\n","from diffusers.optimization import get_scheduler\n","from diffusers.pipelines.stable_diffusion import StableDiffusionSafetyChecker\n","from PIL import Image\n","from torchvision import transforms\n","from tqdm.auto import tqdm\n","from transformers import CLIPFeatureExtractor, CLIPTextModel, CLIPTokenizer\n","# 事前学習モデルのパス\n","pretrained_model_name_or_path = \"CompVis/stable-diffusion-v1-4\"\n","\n","# トークナイザーとテキストエンコーダーの準備\n","tokenizer = CLIPTokenizer.from_pretrained(\n","    pretrained_model_name_or_path,\n","    subfolder=\"tokenizer\",\n","    use_auth_token=True,\n",")\n","text_encoder = CLIPTextModel.from_pretrained(\n","    pretrained_model_name_or_path, subfolder=\"text_encoder\", use_auth_token=True\n",")\n","# 学習した特徴ベクトルをCLIPに読み込み\n","learned_embeds_path = \"./sd-concept-output/learned_embeds.bin\"\n","def load_learned_embed_in_clip(learned_embeds_path, text_encoder, tokenizer, token=None):\n","  loaded_learned_embeds = torch.load(learned_embeds_path, map_location=\"cpu\")\n","  \n","  # 個別のトークンと特徴ベクトル\n","  trained_token = list(loaded_learned_embeds.keys())[0]\n","  embeds = loaded_learned_embeds[trained_token]\n","\n","  # text_encoderのdtypeにキャスト\n","  dtype = text_encoder.get_input_embeddings().weight.dtype\n","  embeds.to(dtype)\n","\n","  # トークナイザーにトークンを追加\n","  token = token if token is not None else trained_token\n","  num_added_tokens = tokenizer.add_tokens(token)\n","  if num_added_tokens == 0:\n","    raise ValueError(f\"The tokenizer already contains the token {token}. Please pass a different `token` that is not already in the tokenizer.\")\n","  \n","  # トークンの特徴ベクトルのサイズ変更\n","  text_encoder.resize_token_embeddings(len(tokenizer))\n","  \n","  # トークンのIDを取得し特徴ベクトルを割り当てる\n","  token_id = tokenizer.convert_tokens_to_ids(token)\n","  text_encoder.get_input_embeddings().weight.data[token_id] = embeds\n","load_learned_embed_in_clip(learned_embeds_path, text_encoder, tokenizer)\n","# Stable Diffusionパイプラインの準備\n","from torch import autocast\n","\n","pipe = StableDiffusionPipeline.from_pretrained(\n","    pretrained_model_name_or_path,\n","    torch_dtype=torch.float16,\n","    text_encoder=text_encoder,\n","    tokenizer=tokenizer,\n","    use_auth_token=True,\n",").to(\"cuda\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3HsKtZ_xJpQs"},"outputs":[],"source":["!pip install -U flask-cors\n","!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip ngrok-stable-linux-amd64.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rzPaOsYdKFlr"},"outputs":[],"source":["get_ipython().system_raw('./ngrok http 6006 &')\n","!curl -s http://localhost:4040/api/tunnels | python3 -c \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""]},{"cell_type":"code","source":["from flask import Flask, render_template,jsonify, request\n","from flask_cors import CORS \n","\n","import base64\n","from PIL import Image\n","import uuid\n","\n","app = Flask(__name__)\n","CORS(app)\n","\n","\n","def image_file_to_base64(file_path):\n","    with open(file_path, \"rb\") as image_file:\n","        data = base64.b64encode(image_file.read())\n","    return data.decode('utf-8')\n","\n","num_samples = 4 # 画像数\n","num_rows = 1 #出力回数\n","\n","def image_file_to_base64(file_path):\n","    with open(file_path, \"rb\") as image_file:\n","        data = base64.b64encode(image_file.read())\n","    return data.decode('utf-8')\n","\n","@app.route(\"/\", methods=['GET','POST'])\n","def index():\n","  prompt=request.args.get('prompt')\n","  \n","  #推論の実行\n","  all_images = [] \n","  for _ in range(num_rows):\n","      with autocast(\"cuda\"):\n","          images = pipe([prompt] * num_samples, num_inference_steps=50, guidance_scale=7.5)[\"sample\"]\n","          all_images.extend(images)\n","  res = []\n","  if not os.path.exists('./buf'):\n","    os.mkdir('./buf')\n","  for img in all_images:\n","    id=str(uuid.uuid4())\n","    img.save(f\"buf/{id}.png\")\n","    res.append(image_file_to_base64(f\"buf/{id}.png\"))\n","\n","  return jsonify({\"image\":res})\n","\n","if __name__ == '__main__':\n","    app.run(port=6006)"],"metadata":{"id":"iShTaazZoWGl"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[],"authorship_tag":"ABX9TyN/Ji/b7P1bvubA7W11ZDSa"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}